Description:
We are seeking a skilled Big Data Engineer to design, develop, and maintain scalable data pipelines for processing and analyzing large datasets. You will work with distributed computing technologies to optimize data workflows and support data-driven decision-making.

Responsibilities:
Design and implement data pipelines for large-scale processing.
Optimize data storage and retrieval for performance and scalability.
Work with cloud-based and on-premises big data technologies.
Ensure data security, integrity, and compliance.
Collaborate with data scientists and analysts to support business needs.
Qualifications:
Bachelor's/MasterÂ’s degree in Computer Science, Data Engineering, or related field.
Experience with Hadoop, Spark, Kafka, and distributed computing.
Proficiency in SQL, Python, or Scala for data processing.
Knowledge of cloud platforms like AWS, Azure, or GCP.
Strong problem-solving and analytical skills.